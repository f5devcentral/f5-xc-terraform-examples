apiVersion: v1
kind: Namespace
metadata:
  name: genai-apps
---
#llama.llm service exposed from EKS will be created in llm namespace
apiVersion: v1
kind: Namespace
metadata:
  name: llm
---

apiVersion: v1
kind: Service
metadata:
  name: langchain-search
  labels:
    app: langchain-search
  namespace: genai-apps
spec:
  type: ClusterIP
  ports:
  - port: 8501
  selector:
    app: langchain-search

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: langchain-search
  namespace: genai-apps
spec:
  selector:
    matchLabels:
      app: langchain-search
  replicas: 1
  template:
    metadata:
      labels:
        app: langchain-search
    spec:
      containers:
      - name: langchain-search
        image: registry.gitlab.com/f5-public/langchain-search:latest
        imagePullPolicy: Always
        ports:
        - containerPort: 8501
        env:
          - name: OPENAI_API_BASE
            value: "http://llama.llm/v1"